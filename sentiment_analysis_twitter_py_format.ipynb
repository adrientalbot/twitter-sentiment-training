{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis_twitter(string_buzzword):\n",
    "    # import libraries:\n",
    "    import twitter\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    # Authenticating our twitter API credentials\n",
    "    twitter_api = twitter.Api(consumer_key='f2ujCRaUnQJy4PoiZvhRQL4n4',\n",
    "                            consumer_secret='EjBSQirf7i83T7CX90D5Qxgs9pTdpIGIsVAhHVs5uvd0iAcw5V',\n",
    "                            access_token_key='1272989631404015616-5XMQkx65rKfQU87UWAh40cMf4aCzSq',\n",
    "                            access_token_secret='emfWcF8fyfqoyywfPCJnz4jXt6DFXfndro59UK9IMAMgy')\n",
    "\n",
    "    # Test authentication to make sure it was successful\n",
    "    #print(twitter_api.VerifyCredentials())\n",
    "    \n",
    "    def buildTestSet(search_keyword):\n",
    "        try:\n",
    "            tweets_fetched = twitter_api.GetSearch(search_keyword, count = 100)\n",
    "\n",
    "            print(\"Fetched \" + str(len(tweets_fetched)) + \" tweets for the term \" + search_keyword)\n",
    "\n",
    "            return [{\"text\":status.text, \"label\":None} for status in tweets_fetched]\n",
    "        except:\n",
    "            print(\"Unfortunately, something went wrong..\")\n",
    "            return None\n",
    "        \n",
    "    #search_term = input(\"Enter a search keyword:\")\n",
    "    testDataSet = buildTestSet(string_buzzword)\n",
    "    \n",
    "    trainingData_copied = pd.read_csv(\"tweetDataFile.csv\", header = None, names = ['tweet_id', 'text', 'label', 'topic'])\n",
    "\n",
    "    df = trainingData_copied.copy()\n",
    "    lst_labels = df['label'].unique()\n",
    "    count_rows_keep = df['label'].value_counts().min()\n",
    "\n",
    "    neutral_df = df[df['label'] == 'neutral'].sample(n= count_rows_keep , random_state = 3)\n",
    "    irrelevant_df = df[df['label'] == 'irrelevant'].sample(n= count_rows_keep , random_state = 2)\n",
    "    negative_df = df[df['label'] == 'negative'].sample(n= count_rows_keep , random_state = 1)\n",
    "    positive_df = df[df['label'] == 'positive'].sample(n= count_rows_keep , random_state = 1)\n",
    "\n",
    "    lst_df = [neutral_df, irrelevant_df, negative_df, positive_df]\n",
    "\n",
    "    trainingData_copied = pd.concat(lst_df)\n",
    "    \n",
    "    trainingData_copied = trainingData_copied.to_dict('records')\n",
    "    \n",
    "    import re #a library that makes parsing strings and modifying them more efficient\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    from string import punctuation \n",
    "    from nltk.corpus import stopwords \n",
    "    import nltk #Natural Processing Toolkit that takes care of any processing that we need to perform on text \n",
    "                #to change its form or extract certain components from it.\n",
    "\n",
    "    #nltk.download('popular') #We need this if certain nltk libraries are not installed. \n",
    "\n",
    "    class PreProcessTweets:\n",
    "        def __init__(self):\n",
    "            self._stopwords = set(stopwords.words('english') + list(punctuation) + ['AT_USER','URL'])\n",
    "\n",
    "        def processTweets(self, list_of_tweets):\n",
    "            processedTweets=[]\n",
    "            for tweet in list_of_tweets:\n",
    "                processedTweets.append((self._processTweet(tweet[\"text\"]),tweet[\"label\"]))\n",
    "            return processedTweets\n",
    "\n",
    "        def _processTweet(self, tweet):\n",
    "            tweet = tweet.lower() # convert text to lower-case\n",
    "            tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', tweet) # remove URLs\n",
    "            tweet = re.sub('@[^\\s]+', 'AT_USER', tweet) # remove usernames\n",
    "            tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet) # remove the # in #hashtag\n",
    "            tweet = word_tokenize(tweet) # remove repeated characters (helloooooooo into hello)\n",
    "            return [word for word in tweet if word not in self._stopwords]\n",
    "        \n",
    "        \n",
    "    tweetProcessor = PreProcessTweets()\n",
    "    preprocessedTrainingSet = tweetProcessor.processTweets(trainingData_copied)\n",
    "    preprocessedTestSet = tweetProcessor.processTweets(testDataSet)\n",
    "    \n",
    "    import nltk \n",
    "\n",
    "    def buildVocabulary(preprocessedTrainingData):\n",
    "        all_words = []\n",
    "\n",
    "        for (words, sentiment) in preprocessedTrainingData:\n",
    "            all_words.extend(words)\n",
    "\n",
    "        wordlist = nltk.FreqDist(all_words)\n",
    "        word_features = wordlist.keys()\n",
    "\n",
    "        return word_features\n",
    "    \n",
    "    def extract_features(tweet):\n",
    "        tweet_words = set(tweet)\n",
    "        features = {}\n",
    "        for word in word_features:\n",
    "            features['contains(%s)' % word] = (word in tweet_words)\n",
    "        return features \n",
    "    \n",
    "    word_features = buildVocabulary(preprocessedTrainingSet)\n",
    "    trainingFeatures = nltk.classify.apply_features(extract_features, preprocessedTrainingSet)\n",
    "    \n",
    "    NBayesClassifier = nltk.NaiveBayesClassifier.train(trainingFeatures)\n",
    "\n",
    "    #We now run the classifier and test it on 100 tweets previously downloaded in the test set, on our specified keyword.\n",
    "\n",
    "    NBResultLabels = [NBayesClassifier.classify(extract_features(tweet[0])) for tweet in preprocessedTestSet]\n",
    "\n",
    "    # get the majority vote\n",
    "    if NBResultLabels.count('positive') > NBResultLabels.count('negative'):\n",
    "        print(\"Overall Positive Sentiment\")\n",
    "        print(\"Positive Sentiment Percentage = \" + str(100*NBResultLabels.count('positive')/len(NBResultLabels)) + \"%\")\n",
    "    else: \n",
    "        print(\"Overall Negative Sentiment\")\n",
    "        print(\"Negative Sentiment Percentage = \" + str(100*NBResultLabels.count('negative')/len(NBResultLabels)) + \"%\")\n",
    "        print(\"Positive Sentiment Percentage = \" + str(100*NBResultLabels.count('positive')/len(NBResultLabels)) + \"%\")\n",
    "        print(\"Number of negative comments = \" + str(NBResultLabels.count('negative')))\n",
    "        print(\"Number of positive comments = \" + str(NBResultLabels.count('positive')))\n",
    "        print(\"Number of neutral comments = \" + str(NBResultLabels.count('neutral')))\n",
    "        print(\"Number of irrelevant comments = \" + str(NBResultLabels.count('irrelevant')))\n",
    "    \n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "    sentiment = [\"Negative\",\"Positive\",\"Neutral\", \"Irrelevant\"]\n",
    "\n",
    "    fig = go.Figure([go.Bar(x=sentiment, y=[str(NBResultLabels.count('negative')), str(NBResultLabels.count('positive')), str(NBResultLabels.count('neutral')), str(NBResultLabels.count('irrelevant'))])])\n",
    "    fig.update_layout(title_text='Sentiment Results for Specific Keyword')\n",
    "\n",
    "    fig.update_layout(template = 'simple_white',\n",
    "        title_text='Twitter Sentiment Results', \n",
    "        yaxis=dict(\n",
    "        title='Percentage (%)',\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=14,) ,\n",
    "\n",
    "\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sentiment_analysis_twitter('FinTech')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
